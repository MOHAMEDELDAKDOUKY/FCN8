{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/divamgupta/image-segmentation-keras/blob/master/Models/FCN8.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "\n",
    "# crop o1 wrt o2\n",
    "def crop( o1 , o2 , i  ):\n",
    "\to_shape2 = Model( i  , o2 ).output_shape\n",
    "\toutputHeight2 = o_shape2[1]\n",
    "\toutputWidth2 = o_shape2[2]\n",
    "\n",
    "\to_shape1 = Model( i  , o1 ).output_shape\n",
    "\toutputHeight1 = o_shape1[1]\n",
    "\toutputWidth1 = o_shape1[2]\n",
    "\n",
    "\tcx = abs( outputWidth1 - outputWidth2 )\n",
    "\tcy = abs( outputHeight2 - outputHeight1 )\n",
    "\n",
    "\tif outputWidth1 > outputWidth2:\n",
    "\t\to1 = Cropping2D( cropping=((0,0) ,  (  0 , cx )), data_format=IMAGE_ORDERING  )(o1)\n",
    "\telse:\n",
    "\t\to2 = Cropping2D( cropping=((0,0) ,  (  0 , cx )), data_format=IMAGE_ORDERING  )(o2)\n",
    "\t\n",
    "\tif outputHeight1 > outputHeight2 :\n",
    "\t\to1 = Cropping2D( cropping=((0,cy) ,  (  0 , 0 )), data_format=IMAGE_ORDERING  )(o1)\n",
    "\telse:\n",
    "\t\to2 = Cropping2D( cropping=((0, cy ) ,  (  0 , 0 )), data_format=IMAGE_ORDERING  )(o2)\n",
    "\n",
    "\treturn o1 , o2 \n",
    "\n",
    "def FCN88( nClasses ,  input_height = 375 , input_width = 1242 , vgg_level=3):\n",
    "\n",
    "\t# assert input_height%32 == 0\n",
    "\t# assert input_width%32 == 0\n",
    "\n",
    "\t# https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_th_dim_ordering_th_kernels.h5\n",
    "\timg_input = Input(shape=(input_height,input_width,3))\n",
    "\n",
    "\tx = Conv2D(64, (3, 3),  padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "\tx = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf1 = x\n",
    "\t# Block 2\n",
    "\tx = Conv2D(128, (3, 3),  padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf2 = x\n",
    "\n",
    "\t# Block 3\n",
    "\tx = Conv2D(256, (3, 3),  padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(256, (3, 3),  padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf3 = x\n",
    "\n",
    "\t# Block 4\n",
    "\tx = Conv2D(512, (3, 3),  padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(512, (3, 3),  padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf4 = x\n",
    "\n",
    "\t# Block 5\n",
    "\tx = Conv2D(512, (3, 3),  padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(512, (3, 3),  padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "\tx = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)\n",
    "\tf5 = x\n",
    "\n",
    "\t#x = Flatten(name='flatten')(x)\n",
    "\t#x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "\t#x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "\t#x = Dense( 1000 , activation='softmax', name='predictions')(x)\n",
    "\n",
    "\tvgg  = Model(  img_input , x  )\n",
    "\tvgg.load_weights(VGG_Weights_path)\n",
    "\n",
    "\to = f5\n",
    "\n",
    "\t#o = ( Conv2D( 4096 , ( 7 , 7 ) , activation='relu' , padding='same', data_format=IMAGE_ORDERING))(o)\n",
    "\t#o = Dropout(0.5)(o)\n",
    "\t#o = ( Conv2D( 4096 , ( 1 , 1 ) , activation='relu' , padding='same', data_format=IMAGE_ORDERING))(o)\n",
    "\t#o = Dropout(0.5)(o)\n",
    "\n",
    "\to = ( Conv2D( nClasses ,  ( 1 , 1 ) ,kernel_initializer='he_normal' , data_format=IMAGE_ORDERING))(o)\n",
    "\to = Conv2DTranspose( nClasses , kernel_size=(4,4) ,  strides=(2,2) , use_bias=False, data_format=IMAGE_ORDERING )(o)\n",
    "\n",
    "\to2 = f4\n",
    "\to2 = ( Conv2D( nClasses ,  ( 1 , 1 ) ,kernel_initializer='he_normal' , data_format=IMAGE_ORDERING))(o2)\n",
    "\t\n",
    "\to , o2 = crop( o , o2 , img_input )\n",
    "\t\n",
    "\to = Add()([ o , o2 ])\n",
    "\n",
    "\to = Conv2DTranspose( nClasses , kernel_size=(4,4) ,  strides=(2,2) , use_bias=False, data_format=IMAGE_ORDERING )(o)\n",
    "\to2 = f3 \n",
    "\to2 = ( Conv2D( nClasses ,  ( 1 , 1 ) ,kernel_initializer='he_normal' , data_format=IMAGE_ORDERING))(o2)\n",
    "\to2 , o = crop( o2 , o , img_input )\n",
    "\to  = Add()([ o2 , o ])\n",
    "\n",
    "\n",
    "\to = Conv2DTranspose( nClasses , kernel_size=(16,16) ,  strides=(8,8) , use_bias=False, data_format=IMAGE_ORDERING )(o)\n",
    "\t\n",
    "\to_shape = Model(img_input , o ).output_shape\n",
    "\t\n",
    "\toutputHeight = o_shape[1]\n",
    "\toutputWidth = o_shape[2]\n",
    "\n",
    "\to = (Activation('softmax'))(o)\n",
    "\n",
    "\t#extra_width =  outputWidth   \n",
    "\n",
    "    \n",
    "\to = Cropping2D( cropping=((1,0) ,  (3 , 3)), data_format=IMAGE_ORDERING  )(o)\n",
    "    \n",
    "\tmodel = Model( img_input , o )\n",
    "    \n",
    "\tmodel.outputWidth = outputWidth\n",
    "\tmodel.outputHeight = outputHeight\n",
    "\n",
    "\treturn model\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#\tm = FCN8( 101 )\n",
    "#\tfrom keras.utils import plot_model\n",
    "#\tplot_model( m , show_shapes=True , to_file='model.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = \"KITTI_MOD_fixed\"\n",
    "dir_seg = dir_data + \"/training/mask/\"\n",
    "dir_img = dir_data + \"/training/images/\"\n",
    "dir_seg_test = dir_data + \"/testing/mask/\"\n",
    "dir_img_test = dir_data + \"/testing/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## seaborn has white grid by default so I will get rid of this.\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "\n",
    "ldseg = np.array(os.listdir(dir_seg))\n",
    "## pick the first image file\n",
    "fnm = ldseg[208]\n",
    "print(fnm)\n",
    "\n",
    "## read in the original image and segmentation labels\n",
    "seg = cv2.imread(dir_seg + fnm )/255 # (360, 480, 3)\n",
    "img_is = cv2.imread(dir_img + fnm )\n",
    "print(\"seg.shape={}, img_is.shape={}\".format(seg.shape,img_is.shape))\n",
    "\n",
    "## Check the number of labels\n",
    "mi, ma = np.min(seg), np.max(seg)\n",
    "n_classes = 2\n",
    "print(\"minimum seg = {}, maximum seg = {}, Total number of segmentation classes = {}\".format(mi,ma, n_classes))\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(img_is)\n",
    "ax.set_title(\"original image\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "for k in range(n_classes):\n",
    "    ax = fig.add_subplot(3,n_classes,k+1)\n",
    "    ax.imshow((seg == k)*1.0)\n",
    "    ax.set_title(\"label = {}\".format(k))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def give_color_to_seg_img(seg,n_classes):\n",
    "    '''\n",
    "    seg : (input_width,input_height,3)\n",
    "    '''\n",
    "    \n",
    "    if len(seg.shape)==3:\n",
    "        seg = seg[:,:,0]\n",
    "    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n",
    "    colors = sns.color_palette(\"hls\", n_classes)\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        segc = (seg == c)\n",
    "        seg_img[:,:,0] += (segc*( colors[c][0] ))\n",
    "        seg_img[:,:,1] += (segc*( colors[c][1] ))\n",
    "        seg_img[:,:,2] += (segc*( colors[c][2] ))\n",
    "\n",
    "    return(seg_img)\n",
    "\n",
    "input_height , input_width = 375, 1242 #384, 1248  #288, 960 #384, 1248 # 192 , 640 ##\n",
    "output_height , output_width = 375, 1242 #384, 1248 #288, 960   #384, 1248 # 192 , 640 ##\n",
    "\n",
    "\n",
    "ldseg = np.array(os.listdir(dir_seg))\n",
    "for fnm in ldseg[np.random.choice(len(ldseg),3,replace=False)]:\n",
    "    fnm = fnm.split(\".\")[0]\n",
    "    seg = cv2.imread(dir_seg + fnm + \".png\") # (360, 480, 3)\n",
    "    img_is = cv2.imread(dir_img + fnm + \".png\")\n",
    "    seg_img = give_color_to_seg_img(seg,n_classes)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    ax = fig.add_subplot(1,4,1)\n",
    "    ax.imshow(seg_img)\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,2)\n",
    "    ax.imshow(img_is/255.0)\n",
    "    ax.set_title(\"original image {}\".format(img_is.shape[:2]))\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,3)\n",
    "    ax.imshow(seg_img)\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,4)\n",
    "    ax.imshow(img_is)\n",
    "    ax.set_title(\"resized to {}\".format((output_height , output_width)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageArr( path , width , height ):\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = cv2.resize(img, (width,height))\n",
    "        img = np.float32(img) / 127.5 - 1\n",
    "        return img\n",
    "\n",
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    img = cv2.imread(path, 1)\n",
    "    img = cv2.resize(img, (width,height))\n",
    "    #img = cv2.copyMakeBorder( img, 1, 0, 3, 3, cv2.BORDER_CONSTANT )\n",
    "    img = img[:, : , 0]/255\n",
    "\n",
    "    for c in range(nClasses):\n",
    "        seg_labels[: , : , c ] = (img == c).astype(int)\n",
    "    ##seg_labels = np.reshape(seg_labels, ( width*height,nClasses  ))\n",
    "    return seg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "images = os.listdir(dir_img)\n",
    "images.sort()\n",
    "segmentations  = os.listdir(dir_seg)\n",
    "segmentations.sort()\n",
    "    \n",
    "count = 0    \n",
    "    \n",
    "X = []\n",
    "Y = []\n",
    "for im , seg in zip(images,segmentations) :\n",
    "    X.append( getImageArr(dir_img + im , input_width , input_height )  )\n",
    "    Y.append( getSegmentationArr( dir_seg + seg , n_classes , output_width , output_height )  )\n",
    "\n",
    "X, Y = np.array(X) , np.array(Y)\n",
    "#X = preprocess_input(X)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[1,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import keras, sys, time, warnings\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import pandas as pd \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_Weights_path = \"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "n_classes= 2\n",
    "IMAGE_ORDERING =  \"channels_last\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN88( nClasses = n_classes , input_height = input_height, input_width = input_width )\n",
    "\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_no 404.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(alpha=0.25,gamma=2.0):\n",
    "    def focal_crossentropy(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        \n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1.- K.epsilon())\n",
    "        p_t = (y_true*y_pred) + ((1-y_true)*(1-y_pred))\n",
    "        \n",
    "        alpha_factor = 1\n",
    "        modulating_factor = 1\n",
    "\n",
    "        alpha_factor = y_true*alpha + ((1-alpha)*(1-y_true))\n",
    "        modulating_factor = K.pow((1-p_t), gamma)\n",
    "\n",
    "        # compute the final loss and return\n",
    "        return K.mean(alpha_factor*modulating_factor*bce, axis=-1)\n",
    "    return focal_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr=1E-2 , decay=5**(-4), momentum=0.9, nesterov=True)\n",
    "#adam = optimizers.Adam(lr=1e-2)\n",
    "\n",
    "#sgd = optimizers.SGD(lr=1)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X,Y, batch_size=4 ,epochs=20,  shuffle = True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['loss']:\n",
    "    plt.plot(hist.history[key],label=key)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('FCN_last.h5')\n",
    "model.save_weights('FCN_last_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('FCN_last.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(dir_img_test)\n",
    "images.sort()\n",
    "segmentations  = os.listdir(dir_seg_test)\n",
    "segmentations.sort()\n",
    "    \n",
    "X_test = []\n",
    "Y_test = []\n",
    "for im , seg in zip(images,segmentations) :\n",
    "    X_test.append( getImageArr(dir_img_test + im , input_width , input_height )  )\n",
    "    Y_test.append( getSegmentationArr( dir_seg_test + seg , n_classes , output_width , output_height )  )\n",
    "\n",
    "X_test, Y_test = np.array(X_test) , np.array(Y_test)\n",
    "#X_test = preprocess_input(X_test)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, batch_size=4, verbose=2)\n",
    "y_predi = np.argmax(y_pred, axis=3)\n",
    "y_testi = np.argmax(Y_test, axis=3)\n",
    "print(y_testi.shape,y_predi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fheight = output_height\n",
    "fwidth = output_width\n",
    "print (fwidth , fheight)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('FCN_last.avi',fourcc, 20.0, (fwidth,fheight))\n",
    "\n",
    "for k in  range(349):\n",
    "    img = (X_test[k] + 1)*(255.0/2)\n",
    "    img = cv2.resize(img, ( output_width , output_height))\n",
    "\n",
    "    mask_img = y_predi[k]*255\n",
    "       \n",
    "    for i in range(mask_img.shape[0]-2):\n",
    "        for j in range (mask_img.shape[1]-2):\n",
    "            if mask_img[i,j]> img[i,j,1]:\n",
    "                img[i,j,1] = mask_img[i,j]\n",
    "                if  img[i,j,0]> 50:\n",
    "                    img[i,j,0] = 50\n",
    "                #elif boxes_img[i,j,2]> 100:\n",
    "                #     boxes_img[i,j,2] = 100   \n",
    "    #img = np.uint8(255 * img) \n",
    "    img = np.array(img, dtype='uint8')\n",
    "    #img = cv2.resize(img , (fwidth,fheight))   \n",
    "    out.write(img)\n",
    "    cv2.imshow('IMG ', img)\n",
    "    k = cv2.waitKey(20)\n",
    "    if k == 27: \n",
    "        break\n",
    "        \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "print ('out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(Yi,y_predi):\n",
    "    ## mean Intersection over Union\n",
    "    ## Mean IoU = TP/(FN + TP + FP)\n",
    "\n",
    "    IoUs = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F_Score = []\n",
    "    \n",
    "    Nclass = int(np.max(Yi)) + 1\n",
    "    for c in range(Nclass):\n",
    "        TP = np.sum( (Yi == c)&(y_predi==c) )\n",
    "        FP = np.sum( (Yi != c)&(y_predi==c) )\n",
    "        FN = np.sum( (Yi == c)&(y_predi != c)) \n",
    "        TN = np.sum( (Yi != c)&(y_predi != c))\n",
    "        IoU = TP/float(TP + FP + FN)\n",
    "        precision = TP/float(TP + FP)\n",
    "        recall = TP/float(TP + FN)\n",
    "        f_score =  2*((precision * recall)/(precision + recall))\n",
    "        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\\Precision={:4.3f}  ,Recall={:4.3f}  ,F_Score={:4.3f}\".format(c,TP,FP,FN,IoU,precision,recall,f_score))\n",
    "        IoUs.append(IoU)\n",
    "        Precision.append(precision)\n",
    "        Recall.append(recall)\n",
    "        F_Score.append(f_score)\n",
    "    mIoU = np.mean(IoUs)\n",
    "    mPrecision = np.mean(Precision)\n",
    "    mRecall = np.mean(Recall)\n",
    "    mF_Score = np.mean(F_Score)\n",
    "    print(\"_________________\")\n",
    "    print(\"Mean IoU: {:4.3f}\".format(mIoU)) \n",
    "    print(\"_________________\")\n",
    "    print(\"Mean Precision: {:4.3f}\".format(mPrecision))\n",
    "    print(\"_________________\")\n",
    "    print(\"Mean Recall: {:4.3f}\".format(mRecall))\n",
    "    print(\"_________________\")\n",
    "    print(\"Mean F_Score: {:4.3f}\".format(mF_Score))\n",
    "\n",
    "\n",
    "IoU(y_testi,y_predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    img_is  = (X_test[i] + 1)*(255.0/2)\n",
    "    seg = y_predi[i]\n",
    "    segtest = y_testi[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(30,90))    \n",
    "    ax = fig.add_subplot(1,3,1)\n",
    "    ax.imshow(img_is/255.0)\n",
    "    ax.set_title(\"original\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,2)\n",
    "    ax.imshow(give_color_to_seg_img(seg,n_classes))\n",
    "    ax.set_title(\"predicted class\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    ax.imshow(give_color_to_seg_img(segtest,n_classes))\n",
    "    ax.set_title(\"true class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
